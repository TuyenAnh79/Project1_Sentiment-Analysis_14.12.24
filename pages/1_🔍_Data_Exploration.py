import streamlit as st
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from wordcloud import WordCloud
from collections import Counter
from utils import *


#################### SET SIDEBAR, PAGE TITLE


st.set_page_config(page_title="Data Exploration", page_icon="üîç")
st.title("üîç Inside the Data:")

st.sidebar.success("Gi√°o Vi√™n H∆∞·ªõng D·∫´n: \n # KHU·∫§T THU·ª≤ PH∆Ø∆†NG")
st.sidebar.success("H·ªçc Vi√™n:\n # NGUY·ªÑN CH·∫§N NAM \n # CH·∫æ TH·ªä ANH TUY·ªÄN")
st.sidebar.success("Ng√†y b√°o c√°o: \n # 16/12/2024")

################################ BI·ªÇU ƒê·ªí T·ªîNG QUAN V·ªÄ B√åNH LU·∫¨N V√Ä S·∫¢N PH·∫®M

san_pham = pd.read_csv('data/San_pham.csv', index_col='ma_san_pham')
danh_gia= pd.read_csv('data/Danh_gia.csv', index_col=0)
khach_hang= pd.read_csv('data/Khach_hang.csv', index_col='ma_khach_hang')

# H√†m ph√¢n lo·∫°i d·ª±a tr√™n gi√° tr·ªã c·ªßa c·ªôt 'so_sao'
def classify_rating(star_rating):
    if star_rating <= 4:
        return 'negative'
    elif star_rating == 5:
        return 'positive'

# √Åp d·ª•ng h√†m v√†o c·ªôt 'so_sao' ƒë·ªÉ t·∫°o c·ªôt m·ªõi 'phan_loai_danh_gia'
danh_gia['phan_loai_danh_gia'] = danh_gia['so_sao'].apply(classify_rating)


danhgia_sanpham = danh_gia.merge(san_pham,on="ma_san_pham", how='left')
df=danhgia_sanpham[['ma_khach_hang','ma_san_pham','ngay_binh_luan','gio_binh_luan','noi_dung_binh_luan','phan_loai_danh_gia','so_sao','ten_san_pham','gia_ban']]

# ƒê√°nh d·∫•u c·ªôt c√≥ b√¨nh lu·∫≠n
df['co_binh_luan'] = df['noi_dung_binh_luan'].notnull() & df['noi_dung_binh_luan'].str.strip().astype(bool)

# T√≠nh s·ªë l∆∞·ª£ng b√¨nh lu·∫≠n t√≠ch c·ª±c, ti√™u c·ª±c v√† kh√¥ng c√≥ b√¨nh lu·∫≠n
# ƒê·∫øm s·ªë l∆∞·ª£ng s·∫£n ph·∫©m duy nh·∫•t
total_products = san_pham.index.nunique()
total_products_eval = df['ma_san_pham'].nunique()
total_eval= df['so_sao'].count()
total_comments = df['noi_dung_binh_luan'].count()
positive_count = df[(df['phan_loai_danh_gia'] == 'positive') & (df['co_binh_luan'])].shape[0]
negative_count = df[(df['phan_loai_danh_gia'] == 'negative') & (df['co_binh_luan'])].shape[0]
no_comment_count = df[~df['co_binh_luan']].shape[0]

# D·ªØ li·ªáu cho bi·ªÉu ƒë·ªì
categories = ['T√≠ch c·ª±c', 'Ti√™u c·ª±c', 'Kh√¥ng c√≥ b√¨nh lu·∫≠n']
values = [positive_count, negative_count, no_comment_count]
colors = sns.color_palette("pastel", len(categories))

# # Hi·ªÉn th·ªã th√¥ng tin 
st.subheader("1. T·ªïng quan v·ªÅ ƒë√°nh gi√° v√† s·∫£n ph·∫©m")

# T·∫°o hai c·ªôt
col1, col2 = st.columns(2)
with col1:
    st.write(f"- SL S·∫£n ph·∫©m: {total_products:,}")
    st.write(f'- SL S·∫£n ph·∫©m c√≥ ƒë√°nh gi√°: {total_products_eval}')
    st.write(f"- SL ƒê√°nh gi√°: {total_eval:,}")
    st.write(f"- SL B√¨nh lu·∫≠n: {total_comments:,}")


# C·ªôt 2: Hi·ªÉn th·ªã s·∫£n ph·∫©m kh√¥ng c√≥ b√¨nh lu·∫≠n
with col2:
    st.write(f"- SL ƒë√°nh gi√° t√≠ch c·ª±c: {positive_count:,}")
    st.write(f"- SL ƒë√°nh gi√° ti√™u c·ª±c: {negative_count:,}")
    st.write(f"- SL c√≥ ƒë√°nh gi√°, nh∆∞ng kh√¥ng b√¨nh lu·∫≠n: {no_comment_count:,}")


# V·∫Ω bi·ªÉu ƒë·ªì Bar Chart
fig, ax = plt.subplots(figsize=(8, 6))
bars = ax.bar(categories, values, color=colors, edgecolor='black')

# Th√™m s·ªë l∆∞·ª£ng tr√™n ƒë·∫ßu m·ªói c·ªôt
for bar in bars:
    height = bar.get_height()
    ax.text(bar.get_x() + bar.get_width() / 2, height + 0.1, str(height),
            ha='center', fontsize=12, color='black')

# ƒê·ªãnh d·∫°ng bi·ªÉu ƒë·ªì
ax.set_title('Ph√¢n lo·∫°i ƒë√°nh gi√° theo s·∫£n ph·∫©m', fontsize=14)
ax.set_ylabel('S·ªë l∆∞·ª£ng s·∫£n ph·∫©m', fontsize=12)
ax.set_xlabel('Lo·∫°i ƒë√°nh gi√°', fontsize=12)
ax.set_ylim(0, max(values) + 1000)

# Hi·ªÉn th·ªã bi·ªÉu ƒë·ªì trong Streamlit
st.pyplot(fig)

################################ BI·ªÇU ƒê·ªí PH√ÇN T√çCH S·ªê L∆Ø·ª¢NG B√åNH LU·∫¨N THEO TH·ªúI GIAN

# Hi·ªÉn th·ªã th√¥ng tin 
st.subheader("2. S·ªë l∆∞·ª£ng b√¨nh lu·∫≠n theo th·ªùi gian")

# Chuy·ªÉn ƒë·ªïi c·ªôt 'ngay_binh_luan' sang ki·ªÉu datetime, lo·∫°i b·ªè c√°c gi√° tr·ªã kh√¥ng h·ª£p l·ªá
df['ngay_binh_luan'] = pd.to_datetime(df['ngay_binh_luan'], format='%d/%m/%Y', errors='coerce')

# Lo·∫°i b·ªè c√°c d√≤ng c√≥ gi√° tr·ªã NaT (Not a Time) trong c·ªôt 'ngay_binh_luan'
df_binhluan = df.dropna(subset=['ngay_binh_luan'])

# Nh√≥m d·ªØ li·ªáu theo th√°ng v√† lo·∫°i ƒë√°nh gi√° (positive/negative)
df_binhluan['thang_nam'] = df_binhluan['ngay_binh_luan'].dt.to_period('M')  # T·∫°o c·ªôt 'thang_nam' theo ƒë·ªãnh d·∫°ng th√°ng-nƒÉm
df_binhluan['phan_loai_danh_gia'] = df_binhluan['phan_loai_danh_gia'].str.lower()  # ƒê·∫£m b·∫£o c·ªôt 'phan_loai_danh_gia' l√† ch·ªØ th∆∞·ªùng

# T√≠nh s·ªë l∆∞·ª£ng b√¨nh lu·∫≠n t√≠ch c·ª±c v√† ti√™u c·ª±c theo th√°ng
monthly_comments = df_binhluan.groupby(['thang_nam', 'phan_loai_danh_gia']).size().unstack(fill_value=0)

# L·∫•y c√°c th√°ng c√≥ trong d·ªØ li·ªáu
available_months = sorted(monthly_comments.index.unique())

# ƒê·∫£m b·∫£o r·∫±ng index m·∫∑c ƒë·ªãnh l√† h·ª£p l·ªá (0 <= index < length of available_months)
default_start_index = 0
default_end_index = len(available_months) - 1

# S·ª≠ d·ª•ng st.columns ƒë·ªÉ t·∫°o c√°c c·ªôt ngang cho th√°ng b·∫Øt ƒë·∫ßu v√† th√°ng k·∫øt th√∫c
col1, col2 = st.columns(2)

# T·∫°o c√°c thanh tr∆∞·ª£t ƒë·ªÉ ch·ªçn th√°ng b·∫Øt ƒë·∫ßu v√† th√°ng k·∫øt th√∫c trong c·ªôt ngang
with col1:
    # Ch·ªçn th√°ng b·∫Øt ƒë·∫ßu v·ªõi th√°ng m·∫∑c ƒë·ªãnh l√† th√°ng ƒë·∫ßu ti√™n (index=default_start_index)
    start_month = st.selectbox('Ch·ªçn th√°ng b·∫Øt ƒë·∫ßu', available_months, index=default_start_index)

with col2:
    # Ch·ªçn th√°ng k·∫øt th√∫c v·ªõi th√°ng m·∫∑c ƒë·ªãnh l√† th√°ng cu·ªëi c√πng (index=default_end_index)
    end_month = st.selectbox('Ch·ªçn th√°ng k·∫øt th√∫c', available_months, index=default_end_index)

# L·ªçc d·ªØ li·ªáu d·ª±a tr√™n th√°ng b·∫Øt ƒë·∫ßu v√† th√°ng k·∫øt th√∫c
filtered_data = monthly_comments[(monthly_comments.index >= start_month) & (monthly_comments.index <= end_month)]

# Ch·ªçn c√°c th√°ng c·∫ßn hi·ªÉn th·ªã (v√≠ d·ª•: th√°ng 3, 6, 9, 12)
selected_months = filtered_data.index.month.isin([3, 6, 9, 12])

# V·∫Ω bi·ªÉu ƒë·ªì bar count v·ªõi ph√¢n chia t√≠ch c·ª±c v√† ti√™u c·ª±c
fig, ax = plt.subplots(figsize=(10, 6))

# V·∫Ω c√°c thanh cho b√¨nh lu·∫≠n t√≠ch c·ª±c
ax.bar(filtered_data.index.astype(str)[selected_months], filtered_data['positive'][selected_months], label='T√≠ch c·ª±c', color='#4CB391', alpha=0.7)

# V·∫Ω c√°c thanh cho b√¨nh lu·∫≠n ti√™u c·ª±c
ax.bar(filtered_data.index.astype(str)[selected_months], filtered_data['negative'][selected_months], bottom=filtered_data['positive'][selected_months], label='Ti√™u c·ª±c', color='red', alpha=0.5)

# Th√™m ti√™u ƒë·ªÅ v√† nh√£n
ax.set_title('S·ªë l∆∞·ª£ng b√¨nh lu·∫≠n t√≠ch c·ª±c v√† ti√™u c·ª±c theo th√°ng', fontsize=16)
ax.set_xlabel('Th√°ng', fontsize=12)
ax.set_ylabel('S·ªë l∆∞·ª£ng b√¨nh lu·∫≠n', fontsize=12)

# Xoay nh√£n tr·ª•c X ƒë·ªÉ d·ªÖ ƒë·ªçc
ax.set_xticklabels(filtered_data.index.astype(str)[selected_months], rotation=45)

# Hi·ªÉn th·ªã legend
ax.legend(title='Lo·∫°i ƒë√°nh gi√°')

# Hi·ªÉn th·ªã bi·ªÉu ƒë·ªì trong Streamlit
st.pyplot(fig)

################################ BI·ªÇU ƒê·ªí PH√ÇN PH·ªêI GI√Å S·∫¢N PH·∫®M

# Hi·ªÉn th·ªã th√¥ng tin
st.subheader("3. Bi·ªÉu ƒë·ªì ph√¢n ph·ªëi gi√° s·∫£n ph·∫©m")

# V·∫Ω bi·ªÉu ƒë·ªì ph√¢n ph·ªëi gi√° s·∫£n ph·∫©m
plt.figure(figsize=(10, 6))
sns.histplot(df['gia_ban'], kde=True, bins=30, color='#4CB391', alpha=0.7)

# Th√™m ti√™u ƒë·ªÅ v√† c√°c nh√£n
plt.title('Ph√¢n ph·ªëi gi√° s·∫£n ph·∫©m', fontsize=14)
plt.xlabel('Gi√° s·∫£n ph·∫©m', fontsize=12)
plt.ylabel('T·∫ßn su·∫•t', fontsize=12)

# Hi·ªÉn th·ªã bi·ªÉu ƒë·ªì trong Streamlit
st.pyplot(plt)

############## BI·ªÇU ƒê·ªí ƒê√ÅNH GI√Å THEO NH√ìM GI√Å S·∫¢N PH·∫®M

# Chia nh√≥m gi√° s·∫£n ph·∫©m d·ª±a tr√™n c·ªôt gia_ban
bins = [0, 100000, 500000, float('inf')]  # C√†i ƒë·∫∑t gi√° tr·ªã theo nh√≥m gi√°, v√≠ d·ª• gi√° th·∫•p, trung b√¨nh, cao
labels = ['Gi√° th·∫•p', 'Gi√° trung b√¨nh', 'Gi√° cao']
df['gia_nhom'] = pd.cut(df['gia_ban'], bins=bins, labels=labels, right=False)

# T√≠nh to√°n t·ªâ l·ªá ƒë√°nh gi√° t√≠ch c·ª±c/ti√™u c·ª±c cho t·ª´ng s·∫£n ph·∫©m
sentiment_distribution = df.groupby(['ma_san_pham', 'phan_loai_danh_gia']).size().unstack(fill_value=0)
sentiment_distribution['positive_ratio'] = sentiment_distribution['positive'] / sentiment_distribution.sum(axis=1)
sentiment_distribution['negative_ratio'] = sentiment_distribution['negative'] / sentiment_distribution.sum(axis=1)

# Th√™m th√¥ng tin nh√≥m gi√° v√†o d·ªØ li·ªáu sentiment_distribution
df_sentiment = df.groupby(['ma_san_pham', 'gia_nhom', 'phan_loai_danh_gia']).size().unstack(fill_value=0)

# T√≠nh s·ªë l∆∞·ª£ng ƒë√°nh gi√° t√≠ch c·ª±c v√† ti√™u c·ª±c cho t·ª´ng nh√≥m gi√°
sentiment_by_group = df_sentiment.groupby('gia_nhom')[['positive', 'negative']].sum()

# Chuy·ªÉn dataframe sentiment_by_group th√†nh d·∫°ng d√†i ƒë·ªÉ seaborn v·∫Ω bi·ªÉu ƒë·ªì d·ªÖ d√†ng
sentiment_by_group_reset = sentiment_by_group.reset_index()
sentiment_by_group_melted = sentiment_by_group_reset.melt(id_vars='gia_nhom', value_vars=['positive', 'negative'], 
                                                         var_name='Lo·∫°i ƒë√°nh gi√°', value_name='S·ªë l∆∞·ª£ng')

# H√†m v·∫Ω bi·ªÉu ƒë·ªì
def draw_sentiment_chart():

    # T·∫°o bi·ªÉu ƒë·ªì Seaborn
    plt.figure(figsize=(10, 6))
    sns.barplot(
        data=sentiment_by_group_melted, 
        x='gia_nhom', 
        y='S·ªë l∆∞·ª£ng', 
        hue='Lo·∫°i ƒë√°nh gi√°', 
        dodge=True, 
        palette='Set2'
    )

    # Th√™m ti√™u ƒë·ªÅ v√† nh√£n
    plt.title('T·ªâ l·ªá ƒë√°nh gi√° t√≠ch c·ª±c v√† ti√™u c·ª±c cho t·ª´ng nh√≥m gi√° s·∫£n ph·∫©m', fontsize=14)
    plt.xlabel('Nh√≥m gi√° s·∫£n ph·∫©m', fontsize=12)
    plt.ylabel('S·ªë l∆∞·ª£ng ƒë√°nh gi√°', fontsize=12)
    plt.legend(title='Lo·∫°i ƒë√°nh gi√°')

    # Hi·ªÉn th·ªã bi·ªÉu ƒë·ªì trong Streamlit
    st.pyplot(plt)

st.subheader("4. T·ªâ l·ªá ƒë√°nh gi√° theo nh√≥m gi√° s·∫£n ph·∫©m")
draw_sentiment_chart()

############## S·∫¢N PH·∫®M C√ì ƒê√ÅNH GI√Å CAO NH·∫§T V√Ä TH·∫§P NH·∫§T

# Hi·ªÉn th·ªã th√¥ng tin 
st.subheader("5. S·∫£n ph·∫©m c√≥ ƒë√°nh gi√° th·∫•p nh·∫•t v√† cao nh·∫•t")

# T√≠nh ƒëi·ªÉm ƒë√°nh gi√° trung b√¨nh cho m·ªói s·∫£n ph·∫©m
# Gi·∫£ s·ª≠ c·ªôt 'danh_gia' l√† ƒëi·ªÉm ƒë√°nh gi√° v√† c·ªôt 'san_pham' l√† t√™n s·∫£n ph·∫©m
average_ratings = df.groupby('ma_san_pham')[['so_sao']].mean().reset_index()

# S·∫Øp x·∫øp c√°c s·∫£n ph·∫©m theo ƒëi·ªÉm ƒë√°nh gi√° t·ª´ th·∫•p ƒë·∫øn cao
sorted_ratings = average_ratings.sort_values(by='so_sao')

# Data ch·ª© link h√¨nh s·∫£n ph·∫©m
image_df = pd.read_csv('files_nam/San_pham_Link_Image_Brand.csv')

# K·∫øt h·ª£p d·ªØ li·ªáu h√¨nh ·∫£nh v√† th√¥ng tin s·∫£n ph·∫©m
combined_df = pd.merge(average_ratings, image_df, on="ma_san_pham", how="inner")
combined_df = pd.merge(combined_df, san_pham, on="ma_san_pham", how="inner")
         
# H√†m hi·ªÉn th·ªã h√¨nh ·∫£nh theo s·ªë l∆∞·ª£ng c·ªë ƒë·ªãnh (2 c·ªôt x 3 d√≤ng)
def display_images(df, num_images=6):
    cols = st.columns(2)  # Chia th√†nh 2 c·ªôt
    for i, (_, row) in enumerate(df.iterrows()):
        with cols[i % 2]:  # Chia s·∫£n ph·∫©m v√†o t·ª´ng c·ªôt
            # Hi·ªÉn th·ªã h√¨nh ·∫£nh s·∫£n ph·∫©m
            st.image(row['hinh_anh'], width=300)

            # Hi·ªÉn th·ªã t√™n s·∫£n ph·∫©m d∆∞·ªõi d·∫°ng hyperlink
            st.markdown(
                f"<h5 style='text-align: center; margin: 5px;'>"
                f"<a href='{row['chi_tiet']}' target='_blank'>{row['ten_san_pham']}</a></h5>",
                unsafe_allow_html=True
            )

            # Hi·ªÉn th·ªã gi√° b√°n s·∫£n ph·∫©m
            st.markdown(
                f"<p style='text-align: center; font-size: 16px; color: red; margin: 5px;'>"
                f"<b>Gi√° b√°n: {row['gia_ban']:,} ƒë</b></p>",
                unsafe_allow_html=True
            )

            # Hi·ªÉn th·ªã s·ªë sao ƒë√°nh gi√°
            st.markdown(
                f"<p style='text-align: center; font-size: 14px; color: orange; margin: 5px;'>"
                f"‚≠ê {'‚≠ê' * int(row['so_sao'])} ({row['so_sao']} sao)</p>",
                unsafe_allow_html=True
            )

            # Th√™m kho·∫£ng c√°ch gi·ªØa c√°c d√≤ng s·∫£n ph·∫©m
            if i % 2 == 1:  # Sau m·ªói 2 s·∫£n ph·∫©m
                st.write("")  # Th√™m m·ªôt kho·∫£ng tr·∫Øng
                st.markdown("---")  # Th√™m m·ªôt ƒë∆∞·ªùng k·∫ª ngang ƒë·ªÉ ph√¢n t√°ch


# T·∫°o Tab
tab1_top, tab2_ground = st.tabs(["üõçÔ∏è Danh S√°ch S·∫£n Ph·∫©m c√≥ ƒë√°nh gi√° cao nh·∫•t", "üõçÔ∏è Danh S√°ch S·∫£n Ph·∫©m c√≥ ƒë√°nh gi√° th·∫•p nh·∫•t"])

# N·ªôi dung cho Tab 1: S·∫£n ph·∫©m c√≥ ƒë√°nh gi√° cao nh·∫•t
with tab1_top:
    st.subheader("S·∫£n ph·∫©m ƒë∆∞·ª£c ƒë√°nh gi√° cao nh·∫•t")
    num_images_top = st.session_state.get("num_images_high", 6)  # S·ªë l∆∞·ª£ng h√¨nh ban ƒë·∫ßu: 6
    
    highest_rated = combined_df.tail(10)  # L·∫•y 10 s·∫£n ph·∫©m c√≥ ƒë√°nh gi√° cao nh·∫•t
    display_images(highest_rated.head(num_images_top))  # Hi·ªÉn th·ªã s·∫£n ph·∫©m
    
    # Ki·ªÉm tra n·∫øu c√≤n s·∫£n ph·∫©m ƒë·ªÉ load
    if num_images_top < len(highest_rated):
        if st.button("üîΩ Xem th√™m", key="high_more_tab1"):
            num_images_top += 6  # TƒÉng s·ªë l∆∞·ª£ng s·∫£n ph·∫©m hi·ªÉn th·ªã th√™m 6
            st.session_state.num_images_high = num_images_top
            st.rerun()
    else:
        st.write("üîî ƒê√£ hi·ªÉn th·ªã t·∫•t c·∫£ s·∫£n ph·∫©m!")

    # N√∫t "Thu g·ªçn" (reset v·ªÅ 6 s·∫£n ph·∫©m)
    if num_images_top > 6:
        if st.button("üîº Thu g·ªçn", key="low_collapse_tab1"):
            num_images_top = 6  # Reset v·ªÅ 6 s·∫£n ph·∫©m
            st.session_state.num_images_high = num_images_top  # C·∫≠p nh·∫≠t l·∫°i trong session_state
            st.rerun()  # Reload l·∫°i giao di·ªán



# N·ªôi dung cho Tab 2: S·∫£n ph·∫©m c√≥ ƒë√°nh gi√° th·∫•p nh·∫•t
with tab2_ground:
    st.subheader("S·∫£n ph·∫©m ƒë∆∞·ª£c ƒë√°nh gi√° th·∫•p nh·∫•t")
    num_images_ground = st.session_state.get("num_images_low", 6)  # S·ªë l∆∞·ª£ng h√¨nh ban ƒë·∫ßu: 6

    lowest_rated = combined_df.head(10)  # L·∫•y 10 s·∫£n ph·∫©m c√≥ ƒë√°nh gi√° th·∫•p nh·∫•t
    display_images(lowest_rated.head(num_images_ground))  # Hi·ªÉn th·ªã s·∫£n ph·∫©m

    if num_images_ground < len(lowest_rated):
        if st.button("üîΩ Xem th√™m", key="high_more_tab2"):
            num_images_ground += 6  # TƒÉng s·ªë l∆∞·ª£ng s·∫£n ph·∫©m hi·ªÉn th·ªã th√™m 6
            st.session_state.num_images_low = num_images_ground
            st.rerun()  # S·ª≠ d·ª•ng st.rerun thay cho st.experimental_rerun()
    else:
        st.write("üîî ƒê√£ hi·ªÉn th·ªã t·∫•t c·∫£ s·∫£n ph·∫©m!")

    # N√∫t "Thu g·ªçn" (reset v·ªÅ 6 s·∫£n ph·∫©m)
    if num_images_ground > 6:
        if st.button("üîº Thu g·ªçn", key="low_collapse_tab2"):
            num_images_ground = 6  # Reset v·ªÅ 6 s·∫£n ph·∫©m
            st.session_state.num_images_low = num_images_ground  # C·∫≠p nh·∫≠t l·∫°i trong session_state
            st.rerun()  # Reload l·∫°i giao di·ªán


########################## WORDCLOUD N·ªòI DUNG B√åNH LU·∫¨N TR·ª®C V√Ä SAU KHI X·ª¨ L√ù
# H√ÄM V·∫º WORDCLOUD
def generate_wordcloud_and_top_words(text, stopwords=None, slider_key="slider"):
    """
    T·∫°o Word Cloud v√† tr·∫£ v·ªÅ t·ª´ ƒëi·ªÉn ch·ª©a c√°c t·ª´ ph·ªï bi·∫øn nh·∫•t.
    """
    # T√≠nh t·∫ßn su·∫•t t·ª´
    words = text.split()
    word_counts = Counter(words)

    # Lo·∫°i b·ªè stopwords (n·∫øu c√≥)
    if stopwords:
        word_counts = Counter({word: count for word, count in word_counts.items() if word not in stopwords})

    # Ch·ªâ gi·ªØ l·∫°i c√°c t·ª´ ph·ªï bi·∫øn nh·∫•t th√¥ng qua slider (th√™m key ƒë·ªÉ tr√°nh l·ªói)
    num_words = st.slider("Ch·ªçn s·ªë l∆∞·ª£ng t·ª´ ph·ªï bi·∫øn ƒë·ªÉ hi·ªÉn th·ªã", min_value=5, max_value=50, value=10, step=1, key=slider_key)
    top_words = word_counts.most_common(num_words)
    top_words_dict = dict(top_words)

    # Tr·∫£ v·ªÅ Word Cloud v√† danh s√°ch top t·ª´ ph·ªï bi·∫øn
    wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(top_words_dict)
    return wordcloud, top_words
#----------

# T·∫°o hai tab cho WORD CLOUD
st.header('6. WordCloud CHO B√åNH LU·∫¨N')

# N·ªëi t·∫•t c·∫£ c√°c b√¨nh lu·∫≠n th√†nh m·ªôt vƒÉn b·∫£n
text = " ".join(df['noi_dung_binh_luan'].dropna())

# G·ªçi h√†m v√† chia tab
wordcloud, top_words = generate_wordcloud_and_top_words(text, slider_key="slider")
tab1, tab2 = st.tabs(["Word Cloud ", "Top T·ª´ Ph·ªï Bi·∫øn"])

with tab1:
    fig, ax = plt.subplots(figsize=(10, 5))
    ax.imshow(wordcloud, interpolation='bilinear')
    ax.axis('off')
    st.pyplot(fig)

with tab2:
    for word, count in top_words:
        st.write(f"{word}: {count}")


##################### WC POSITIVE, NEGATIVE WORDS

# POSITIVE
st.subheader("Word Cloud v√† Top T·ª´ POSITIVE Ph·ªï Bi·∫øn")

# Load POSITIVE_WORDS
positive_words = load_and_process_file('files/positive_words_VN.txt')
print("Count of positive_words:", len(positive_words))

# Chuy·ªÉn ƒë·ªïi key, thay kho·∫£ng tr·∫Øng b·∫±ng '_'
list_positive_words = [key.replace(' ', '_') for key in positive_words.keys()]

# Chuy·ªÉn danh s√°ch th√†nh m·ªôt chu·ªói vƒÉn b·∫£n
text_positive_words = ' '.join(list_positive_words)

# Load NEGATIVE_WORDS
negative_words = load_and_process_file('files/negative_words_VN.txt')
print("Count of negative_words:", len(negative_words))

# Chuy·ªÉn ƒë·ªïi key, thay kho·∫£ng tr·∫Øng b·∫±ng '_'
list_negative_words = [key.replace(' ', '_') for key in negative_words.keys()]

# Chuy·ªÉn danh s√°ch th√†nh m·ªôt chu·ªói vƒÉn b·∫£n
text_negative_words = ' '.join(list_negative_words)

# G·ªçi h√†m v√† chia tab
wordcloud_positive, top_words_positive = generate_wordcloud_and_top_words(text_positive_words, slider_key="slider_positive")
tab1_positive, tab2_positive = st.tabs(["Word Cloud POSITIVE", "Top T·ª´ Ph·ªï Bi·∫øn POSITIVE"])

with tab1_positive:
    fig, ax = plt.subplots(figsize=(10, 5))
    ax.imshow(wordcloud_positive, interpolation='bilinear')
    ax.axis('off')
    st.pyplot(fig)

with tab2_positive:
    for word, count in top_words_positive:
        st.write(f"{word}: {count}")

# NEGATIVE
st.subheader("Word Cloud v√† Top T·ª´ NEGATIVE Ph·ªï Bi·∫øn")

# G·ªçi h√†m v√† chia tab
wordcloud_negative, top_words_negative = generate_wordcloud_and_top_words(text_negative_words, slider_key="slider_negative")
tab1_negative, tab2_negative = st.tabs(["Word Cloud NEGATIVE", "Top T·ª´ Ph·ªï Bi·∫øn NEGATIVE"])

with tab1_negative:
    fig, ax = plt.subplots(figsize=(10, 5))
    ax.imshow(wordcloud_negative, interpolation='bilinear')
    ax.axis('off')
    st.pyplot(fig)

with tab2_negative:
    for word, count in top_words_negative:
        st.write(f"{word}: {count}")


###################
# Inside the Data: B√™n trong d·ªØ li·ªáu.
# Data Unveiled: H√© l·ªô d·ªØ li·ªáu.
# Beneath the Numbers: D∆∞·ªõi nh·ªØng con s·ªë.
# Deep Dive into Data: ƒêi s√¢u v√†o d·ªØ li·ªáu.
# Cracking the Data Code: Gi·∫£i m√£ d·ªØ li·ªáu.
